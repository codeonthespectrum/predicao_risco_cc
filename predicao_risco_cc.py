# -*- coding: utf-8 -*-
"""predicao_risco_cc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19N4rYmkiPuX9rFPPIO6J-H0L4NpXNYh_
"""

pip install ucimlrepo

import numpy as np
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from xgboost import XGBClassifier
import matplotlib.pyplot as plt
from ucimlrepo import fetch_ucirepo

"""# EDA - ANALISE EXPLORATORIA DE DADOS"""

statlog_german_credit_data = fetch_ucirepo(id=144)
X = statlog_german_credit_data.data.features
y = statlog_german_credit_data.data.targets

print(statlog_german_credit_data.metadata)
print(statlog_german_credit_data.variables)


print(X.info())
print(y.info())

#estatistica de features

print(X.describe())

#analise de desbalanceamento de classes

print(y['class'].value_counts(normalize=True))

# Plotar histograma para 'credit_amount'
X['Attribute5'].hist(bins=30)
plt.title('Distribuição do Valor do Empréstimo')
plt.show()

# Plotar histograma para 'age'
X['Attribute13'].hist(bins=20)
plt.title('Distribuição da Idade')
plt.show()

# Plotar gráfico de barras para 'purpose'
X['Attribute4'].value_counts().plot(kind='bar')
plt.title('Propósito do Empréstimo')
plt.show()

# Plotar gráfico de barras para 'housing'
X['Attribute15'].value_counts().plot(kind='bar')
plt.title('Tipo de Moradia')
plt.show()

X_copy = X.copy()
y_copy = y.copy()

# 0 (Alto Risco) e 1 -> 1 (Baixo Risco)
# O metadata diz: 1 = good, 2 = bad. Vamos mudar 2 para 0 (bad)
y_copy['risk'] = y_copy['class'].map({1: 1, 2: 0}) # 1 = Bom Risco, 0 = Alto Risco (Bad)

# Juntar
df_full = pd.concat([X_copy, y_copy['risk']], axis=1)

import seaborn as sns

# O 'credit_amount' é diferente para "Bom" e "Alto" risco?
sns.boxplot(data=df_full, x='risk', y='Attribute5')
plt.title('Valor do Empréstimo vs. Risco')
plt.show()

# A 'age' é diferente?
sns.boxplot(data=df_full, x='risk', y='Attribute13')
plt.title('Idade vs. Risco')
plt.show()

pd.crosstab(df_full['Attribute4'], df_full['risk']).plot(kind='bar', stacked=True)
plt.title('Propósito vs. Risco')
plt.show()

# O 'checking_status' afeta o risco?
pd.crosstab(df_full['Attribute1'], df_full['risk']).plot(kind='bar', stacked=True)
plt.title('Status da Conta Corrente vs. Risco')
plt.show()

# 'Attribute1' (Status da Conta) vs. 'risk'
pd.crosstab(df_full['Attribute1'], df_full['risk']).plot(kind='bar', stacked=True)
plt.title('Status da Conta Corrente vs. Risco')
plt.show()

# 'Attribute3' (Histórico de Crédito) vs. 'risk'
pd.crosstab(df_full['Attribute3'], df_full['risk']).plot(kind='bar', stacked=True)
plt.title('Histórico de Crédito vs. Risco')
plt.show()

X_processed = pd.get_dummies(X)
y_processed = y['class'].map({1: 1, 2: 0}) # 1 = Bom Risco, 0 = Alto Risco

print("Formato do X original:", X.shape)
print("Formato do X processado:", X_processed.shape)
print("\nClasses do Y processado:\n", y_processed.value_counts())

"""### Resumo da Análise Exploratória de Dados (EDA)


### 1. As Principais Descobertas

1.  **O Alvo é Desbalanceado:** Composto por **70% de clientes de "Risco Bom"** (classe 1) e **30% de "Risco Ruim"** (classe 2).
    * **Por que isso importa:** Isso força a focar em métricas melhores, como o **Recall**, especialmente porque o *metadata* informa que é 5x pior aprovar um cliente "Ruim".

2.  **Os Dados são Mistos (Numéricos e Texto):** `X` tinha 20 colunas, sendo **7 numéricas** (`int64`) e **13 categóricas** (`object`, ou seja, texto).

3.  **Dados Estão Completos:** nenhum valor faltante (nulo) nas 1000 linhas.

4.  **Existem Preditores Visuais Fortes:** gráficos mostraram "descrepâncias grandes"
    * **Por que isso importa:** `Attribute3` (Histórico de Crédito) e `Attribute1` (Status da Conta) separam visualmente o Risco Bom do Ruim. Por exemplo, a categoria 'A34' (conta crítica) tinha uma proporção muito alta de "Risco Ruim" (azul). Mostra confiança de que o modelo terá "sinal" para aprender.

---


### 2. Preparação para o Modelo

1.  **Mapeamento de Alvo** `y` para `y_processed`, onde **0 = Risco Ruim** e **1 = Risco Bom**.
2.  **Features:** `pd.get_dummies(X)` para transformar as 13 colunas de texto em colunas numéricas (0s e 1s), criando o `X_processed` com 61 colunas.

# Divisão e Treinamento de modelo
"""

X_train, X_test, y_train, y_test = train_test_split(
    X_processed,
    y_processed,
    test_size=0.2,
    random_state=42,
    stratify=y_processed
)

print(f"Formato de X_train: {X_train.shape}")
print(f"Formato de X_test: {X_test.shape}")
print("\nDistribuição do y_train:")
print(y_train.value_counts(normalize=True))
print("\nDistribuição do y_test:")
print(y_test.value_counts(normalize=True))

tree_model = DecisionTreeClassifier(random_state=42)

tree_model.fit(X_train, y_train)

tree_model_v2 = DecisionTreeClassifier(
    max_depth=3,
    random_state=42
)

# 2. Treinar o novo modelo
tree_model_v2.fit(X_train, y_train)
print("--- Resultados do Modelo V2 (max_depth=3) ---")
y_pred_v2 = tree_model_v2.predict(X_test)

print(classification_report(y_test, y_pred_v2, target_names=['Risco Ruim (0)', 'Risco Bom (1)']))

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import seaborn as sns

y_pred = tree_model.predict(X_test)

acc = accuracy_score(y_test, y_pred)
print("{acc:2f}")

cm = confusion_matrix(y_test, y_pred)
print(cm)

sns.heatmap(cm, annot=True, fmt='d', xticklabels=['Prev. Ruim (0)', 'Prev. Bom (1)'], yticklabels=['Real Ruim (0)', 'Real Bom (1)'])
plt.ylabel('Valor Real')
plt.xlabel('Valor Previsto')
plt.title('Matriz de Confusão')
plt.show()

print(classification_report(y_test, y_pred, target_names=['Risco Ruim (0)', 'Risco Bom (1)']))

tree_model_v3 = DecisionTreeClassifier(
    max_depth=5,
    class_weight='balanced',
    random_state=42
)

tree_model_v3.fit(X_train, y_train)
y_pred_v3 = tree_model_v3.predict(X_test)

print(classification_report(y_test, y_pred_v3, target_names=['Risco Ruim (0)', 'Risco Bom (1)']))

cm_v3 = confusion_matrix(y_test, y_pred)
sns.heatmap(cm_v3, annot=True, fmt='d', xticklabels=['Prev. Ruim (0)', 'Prev. Bom (1)'], yticklabels=['Real Ruim (0)', 'Real Bom (1)'])
plt.title('Matriz de Confusão - Modelo V3')
plt.show()

from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

plt.figure(figsize=(20, 10))

feature_names = X_processed.columns

plot_tree(
    tree_model_v3,
    feature_names=feature_names,
    class_names=['Risco Ruim (0)', 'Risco Bom (1)'],
    filled=True,
    rounded=True,
    fontsize=8
)

plt.title("Árvore de Decisão - Modelo Final")
plt.show()